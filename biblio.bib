@inproceedings{Wu15OI,
  title={On Identifying Good Options under Combinatorially Structured Feedback in Finite Noisy Environments},
  author={Wu, Yifan and Gyorgy, Andras and Szepesvari, Csaba},
  booktitle={Proceedings of The 32nd International Conference on Machine Learning},
  pages={1283--1291},
  year={2015}
}

@book{Tambe11SG,
  title={Security and Game Theory: Algorithms, Deployed Systems, Lessons Learned},
  author={Tambe, Milind},
  year={2011},
  publisher={Cambridge University Press}
}

@article{aghassi2006robust,
  title={Robust game theory},
  author={Aghassi, Michele and Bertsimas, Dimitris},
  journal={Mathematical Programming},
  volume={107},
  number={1-2},
  pages={231--273},
  year={2006},
  publisher={Springer}
}

	
	@article{Blum15LP,
  title={Learning to Play Stackelberg Security Games},
  author={Blum, Avrim and Haghtalab, Nika and Procaccia, Ariel D and Br{\^a}nzei, Simina and Caragiannis, Ioannis and Kurokawa, David and Procaccia, Ariel D and Reddi, Sashank J and Shah, Nisarg and Parkes, David C and others},
  year=2015
}

@article{Balcan15CR,
  title={Commitment without regrets: Online learning in Stackelberg security games},
  author={Balcan, Maria-Florina and Blum, Avrim and Haghtalab, Nika and Procaccia, Ariel D},
  year={2015},
  publisher={ACM}
}

@inproceedings{Nguyen14RO,
  title={Regret-based optimization and preference elicitation for stackelberg security games with uncertainty},
  author={Nguyen, Thanh H and Yadav, Amulya and An, Bo and Tambe, Milind and Boutilier, Craig},
  booktitle={Proceedings of the 28th AAAI Conference on Artificial Intelligence (AAAI)},
  pages={756--762},
  year={2014}
}



@inproceedings{Marecki12PR,
 author = {Marecki, Janusz and Tesauro, Gerry and Segal, Richard},
 title = {Playing Repeated Stackelberg Games with Unknown Opponents},
 booktitle = {Proceedings of the 11th International Conference on Autonomous Agents and Multiagent Systems - Volume 2},
 series = {AAMAS '12},
 year = {2012},
 isbn = {0-9817381-2-5, 978-0-9817381-2-3},
 location = {Valencia, Spain},
 pages = {821--828},
 numpages = {8},
acmid = {2343814},
 publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
 address = {Richland, SC},
 keywords = {Monte-Carlo tree search, Stackelberg games}
} 

@inproceedings{pita2008deployed,
  title={Deployed ARMOR protection: the application of a game theoretic model for security at the Los Angeles International Airport},
  author={Pita, James and Jain, Manish and Marecki, Janusz and Ord{\'o}{\~n}ez, Fernando and Portway, Christopher and Tambe, Milind and Western, Craig and Paruchuri, Praveen and Kraus, Sarit},
  booktitle={Proceedings of the 7th international joint conference on Autonomous agents and multiagent systems: industrial track},
  pages={125--132},
  year={2008},
  organization={International Foundation for Autonomous Agents and Multiagent Systems}
}

@article{tsai2009iris,
  title={IRIS-a tool for strategic security allocation in transportation networks},
  author={Tsai, Jason and Kiekintveld, Christopher and Ordonez, Fernando and Tambe, Milind and Rathi, Shyamsunder},
  year={2009}
}

@article{yin2012trusts,
  title={TRUSTS: Scheduling randomized patrols for fare inspection in transit systems using game theory},
  author={Yin, Zhengyu and Jiang, Albert Xin and Tambe, Milind and Kiekintveld, Christopher and Leyton-Brown, Kevin and Sandholm, Tuomas and Sullivan, John P},
  journal={AI Magazine},
  volume={33},
  number={4},
  pages={59},
  year={2012}
}

@inproceedings{shieh2012protect,
  title={Protect: A deployed game theoretic system to protect the ports of the united states},
  author={Shieh, Eric and An, Bo and Yang, Rong and Tambe, Milind and Baldwin, Craig and DiRenzo, Joseph and Maule, Ben and Meyer, Garrett},
  booktitle={Proceedings of the 11th International Conference on Autonomous Agents and Multiagent Systems-Volume 1},
  pages={13--20},
  year={2012},
  organization={International Foundation for Autonomous Agents and Multiagent Systems}
}
@article{lye2005game,
  title={Game strategies in network security},
  author={Lye, Kong-wei and Wing, Jeannette M},
  journal={International Journal of Information Security},
  volume={4},
  number={1},
  pages={71--86},
  year={2005},
  publisher={Springer}
}

@article{korzhyk2011stackelberg, title={Stackelberg vs. Nash in Security Games: An Extended Investigation of Interchangeability, Equivalence, and Uniqueness.}, author={Korzhyk, Dmytro and Yin, Zhengyu and Kiekintveld, Christopher and Conitzer, Vincent and Tambe, Milind}, journal={J. Artif. Intell. Res.(JAIR)}, volume={41}, pages={297--327}, year={2011} }

@inproceedings{tambe2012game,
  title={Game Theory for Security: A Real-World Challenge Problem for Multiagent Systems and Beyond.},
  author={Tambe, Milind and An, Bo},
  booktitle={AAAI Spring Symposium: Game Theory for Security, Sustainability, and Health},
  year={2012}
}

@inproceedings{qian2014online,
  title={Online planning for optimal protector strategies in resource conservation games},
  author={Qian, Yundi and Haskell, William B and Jiang, Albert Xin and Tambe, Milind},
  booktitle={Proceedings of the 2014 international conference on Autonomous agents and multi-agent systems},
  pages={733--740},
  year={2014},
  organization={International Foundation for Autonomous Agents and Multiagent Systems}
}

@inproceedings{Abbasi-Yadkori11IA,
  author    = {Y. Abbasi-Yadkori and
               D. P{\'a}l and
               {\relax Cs}aba Szepesv{\'a}ri},
  title     = {{Improved Algorithms for Linear Stochastic Bandits}},
  booktitle = {Proceedings of the Advances in Neural Information Processing Systems 25},
  year      = {2011},
  pages     = {2312-2320}
}

@ARTICLE{Nedic03LS,
  AUTHOR =       {A. Nedi\'c and D. Bertsekas},
  TITLE =        {{Least Squares Policy Evaluation Algorithms with Linear Function Approximation}},
  JOURNAL =      {Discrete Event Dynamic Systems: Theory and Applications},
  YEAR =         {2003},
  volume =       {13},
  pages =        {79-110}
}

@INPROCEEDINGS{Petrik09BA,
  author = {M. Petrik and B. Scherrer},
  title = {Biasing Approximate Dynamic Programming with a Lower Discount Factor},
  booktitle = {Proceedings of the Advances in Neural Information Processing Systems 23},
  year = {2009}
}

@INPROCEEDINGS{Baird95RA,
    author = {L. Baird},
    title = {Residual Algorithms: Reinforcement Learning with Function Approximation},
    booktitle = {Proceedings of the Twelfth International Conference on Machine Learning},
    year = {1995},
    pages = {30--37},
    publisher = {Morgan Kaufmann}
}

@TECHREPORT{Lazaric10AC-Tech,
  author = {A. Lazaric and M. Ghavamzadeh and R. Munos},
  title = {{Analysis of a Classification-based Policy Iteration Algorithm}},
  institution = {INRIA},
  year = {2010},
  number = {00482065}
}

@Book{Rubinstein04CE,
  author =	 {R. Rubinstein and D. Kroese},
  title = 	 {{The Cross-Entropy Method: A Unified Approach to Combinatorial Optimization, Monte-Carlo Simulation, and Machine Learning}},
  publisher = 	 {Springer-Verlag},
  year = {2004}
}

@INPROCEEDINGS{Gabillon11CP,
    AUTHOR = "V. Gabillon and A. Lazaric and M. Ghavamzadeh and B. Scherrer",
    TITLE = {{Classification-based Policy Iteration with a Critic}},
    BOOKTITLE = "Proceedings of the Twenty-Eighth International Conference on Machine Learning",
    PAGES = "1049-1056",
    YEAR = "2011"}
    
@Article{Munos07PB,
    author    = {R. Munos},
  title     = {{Performance Bounds in L$_{\mbox{p}}$-norm for Approximate Value
               Iteration}},
  journal   = {SIAM Journal on Control and Optimization},
  volume    = {46},
  number    = {2},
  year      = {2007},
  pages     = {541-561} 
  }

@inproceedings{Munos03EB,
  author    = {R. Munos},
  title     = {{Error Bounds for Approximate Policy Iteration}},
  booktitle = {Proceedings of the Twentieth International Conference on Machine Learning},
  year      = 2003,
  pages     = {560-567}
}

@Book{Puterman94MD,
  author =	 {M. Puterman},
  title = 	 {Markov {D}ecision {P}rocesses},
  publisher = 	 {Wiley, New York},
  year = 	 {1994}
}

@inproceedings{Lazaric10AC,
  author    = {Alessandro Lazaric and
               M. Ghavamzadeh and
               R. Munos},
  title     = {{Analysis of a Classification-based Policy Iteration Algorithm}},
  booktitle = {Proceedings of the Twenty-Seventh International Conference on Machine Learning},
  year      = {2010},
  pages     = {607-614}
}

@INPROCEEDINGS{Kearns00AP,
    author = {M. Kearns and Y. Mansour and A. Ng},
    title = {{Approximate Planning in Large POMDPs via Reusable Trajectories}},
    booktitle = {Proceedings of the Advances in Neural Information Processing Systems 14},
    year = {2000},
    pages = {1001--1007},
    publisher = {MIT Press}
}

@inproceedings{Thiery10LS,
    title = {{Least-Squares $\lambda$-Policy Iteration: Bias-Variance Trade-off in Control Problems}},
    author = {C. Thi\'ery and B. Scherrer},
    booktitle = {Proceedings of the Twenty-Seventh International Conference on Machine Learning},
    pages = {1071-1078},
    year = {2010}
}

@techreport{Scherrer10PB,
    title = { {P}erformance bound for {A}pproximate {O}ptimistic {P}olicy {I}teration},
    author = {{S}cherrer, {B}. and {T}hi\'ery, {C}.},
    type = {Technical Report},
    year = {2010},
    institution = {INRIA}
}

@article{Munos08FT,
  author    = {R. Munos and
               {\relax Cs}aba Szepesv{\'a}ri},
  title     = {{Finite-Time Bounds for Fitted Value Iteration}},
  journal   = {Journal of Machine Learning Research},
  volume    = {9},
  year      = {2008},
  pages     = {815-857}
}

@INPROCEEDINGS{Bubeck10OL,
  author = {S. Bubeck and R. Munos},
  title = {{Open Loop Optimistic Planning}},
  booktitle = {Proceedings of the Twenty-Third Conference on Learning Theory},
  year = {2010}
}

@article{Vanroy97AT,
    author = {J. Tsitsiklis and Van Roy, B.},
    title = {{An Analysis of Temporal-Difference Learning with Function Approximation}},
    journal = {IEEE Transactions on Automatic Control},
    volume = {42},
    number = {5},
    pages = {674--690},
    year = {1997}
}

@inproceedings{Farahmand10EP,
	Author = {Farahmand, A.-M. and Munos, R. and Szepesv{\'a}ri, {\relax Cs}aba},
	Booktitle = {Proceedings of the Advances in Neural Information Processing Systems 24},
	Title = {{Error Propagation for Approximate Policy and Value Iteration}},
	pages={568--576},
	Year = {2010}}

@inproceedings{Antos07FQ,
	Author = {A. Antos and R. Munos and {\relax Cs}aba Szepesv{\'a}ri},
	Booktitle = {Proceedings of the Advances in Neural Information Processing Systems 21},
	Pages = {9-16},
	Title = {Fitted {Q}-iteration in Continuous Action-space {MDP}s},
	Year = {2007}}

@inproceedings{Antos07VI,
	Author = {Antos, A. and Szepesv{\'a}ri, {\relax Cs}aba and Munos, R.},
	Booktitle = {{ADPRL} 2007},
	Date-Added = {2010-08-28 17:38:14 -0600},
	Date-Modified = {2010-09-05 00:56:00 -0600},
	Pages = {330--337},
	Pdf = {papers/sapi_adprl4aa.pdf},
	Publisher = {IEEE},
	Title = {{Value-iteration Based Fitted Policy Iteration: Learning with a Single Trajectory}},
	Year = {2007}}

@ARTICLE{Antos08LN,
  author = {A. Antos and {\relax Cs}aba Szepesv{\'a}ri and R. Munos},
  title = {Learning near-optimal policies with {B}ellman-residual minimization
	based fitted policy iteration and a single sample path},
  journal = {Machine Learning Journal},
  year = {2008},
  volume = {71},
  pages = {89-129},
}

@ARTICLE{Bradtke96LL,
  author = {S. Bradtke and A. Barto},
  title = {{Linear Least-Squares Algorithms for Temporal Difference Learning}},
  journal = {Journal of Machine Learning},
  year = {1996},
  volume = {22},
  pages = {33-57}
}

@book{Sutton98RL,
    author = "Sutton, R. and Barto, A.",
    title = {{Reinforcement Learning, An introduction}},
    publisher = "BradFord Book. The MIT Press",
    year = "1998"
}

@TechReport{Ioffe96TD,
  author = 	 {D. Bertsekas and S. Ioffe},
  title = 	 {{Temporal Differences-Based Policy Iteration and Applications in Neuro-Dynamic Programming}},
  institution =  {MIT},
  year = 	 1996,
}

@article{Lagoudakis03LS,
  author    = {M. Lagoudakis and R. Parr},
  title     = {{Least-Squares Policy Iteration}},
  journal   = {Journal of Machine Learning Research}, 
  volume    = {4},
  year      = {2003},
  pages     = {1107-1149},
}

@inproceedings{Lagoudakis03RL,
  author    = {M. Lagoudakis and
               R. Parr},
  title     = {{Reinforcement Learning as Classification: Leveraging Modern
               Classifiers}},
  booktitle = {Proceedings of the Twentieth International Conference on Machine Learning},
  year      = {2003},
  pages     = {424-431},
}

@INPROCEEDINGS{Fern04AP,
  author = {A. Fern and S. Yoon and R. Givan},
  title = {Approximate Policy Iteration with a Policy Language Bias},
  booktitle = {Proceedings of the Advances in Neural Information Processing Systems 18},
  year = {2004}
}
@article{Fern06AP,
  author    = {A. Fern and
               S. Yoon and
               R. Givan},
  title     = {{Approximate Policy Iteration with a Policy Language Bias:
               Solving Relational Markov Decision Processes}},
  journal   = {Journal of  Artificial Intelligence Research},
  volume    = {25},
  year      = {2006},
  pages     = {75-118},
}

@ARTICLE{Devore98NA,
    author = {R. DeVore},
    title = {{Nonlinear Approximation}},
    journal = {Acta Numerica},
    year = {1998},
    volume = {7},
    pages = {51-150}
}

@incollection{Szepesvari10RL,
	Author = {Szepesv{\'a}ri, {\relax Cs}aba},
	Booktitle = {Wiley Encyclopedia of Operations Research},
	Title = {{Reinforcement Learning Algorithms for MDPs}},
	publisher = {Wiley},
	Year = {2010}}

@article{Ernst05TB,
  author    = {D. Ernst and
               P. Geurts and
               L. Wehenkel},
  title     = {{Tree-Based Batch Mode Reinforcement Learning}},
  journal   = {Journal of Machine Learning Research},
  volume    = {6},
  year      = {2005},
  pages     = {503-556},
}

@article{Puterman78MP,
author = {M. Puterman and M. Shin},
title = {{Modified Policy Iteration Algorithms for Discounted Markov Decision Problems}},
journal= {Management Science},
volume    = {24},
number ={11},
year = {1978}
}

@inproceedings{Boyan95GR,
    Year = {1995},
    Pages = {369--376},
    Booktitle = {Proceedings of the Advances in Neural Information Processing Systems 9},
    Author = {J. Boyan and A. Moore},
    Title = {{Generalization in Reinforcement Learning: Safely Approximating the Value Function}}
}

@inproceedings{Maei09CT,
	Author = {Maei, H. and Szepesv{\'a}ri, {\relax Cs}aba and Bhatnagar, S. and Silver, D. and Precup, D. and Sutton, R.},
	Booktitle = {Proceedings of the Advances in Neural Information Processing Systems 23},
	Pages = {1204--1212},
	Title = {{Convergent Temporal-Difference Learning with Arbitrary Smooth Function Approximation}},
	Year = {2009}
}

@InProceedings{Geist10SL,
author = {M. Geist and O. Pietquin},
title = {{Statistically Linearized Least-Squares Temporal Differences}},
year = {2010},
booktitle = {{Proceedings of the IEEE International Conference on Ultra Modern Control systems}},
}

@inproceedings{Precup01OP,
  author    = {D. Precup and
               R. Sutton and
               S. Dasgupta},
  title     = {{Off-Policy Temporal Difference Learning with Function Approximation}},
  booktitle = {Proceedings of the Eighteenth International Conference on Machine Learning},
  year      = {2001},
  pages     = {417--424},
}

@inproceedings{Precup00ET,
  author    = {D. Precup and
               R. Sutton and
               S. Singh},
  title     = {{Eligibility Traces for Off-Policy Policy Evaluation}},
  booktitle = {Proceedings of the Seventeenth International Conference on Machine Learning},
  year      = {2000},
  pages     = {759--766},
}

@TECHREPORT{Lazaric10FS-Tech,
  author = {A. Lazaric and M. Ghavamzadeh and R. Munos},
  title = {{Finite-Sample Analysis of Least-Squares Policy Iteration}},
  institution = {INRIA},
  year = {2010},
  number = {inria-00528596}
}
@inproceedings{Lazaric10FS,
  author    = {Alessandro Lazaric and
               Mohammad Ghavamzadeh and
               R{\'e}mi Munos},
  title     = {{Finite-Sample Analysis of LSTD}},
  booktitle = {Proceedings of the Twenty-Seventh International Conference on Machine
               Learning},
  year      = {2010},
  pages     = {615-622}
}

@article{Lazaric12FS,
   title = {{Finite-Sample Analysis of Least-Squares Policy Iteration}},
    author={Lazaric, Alessandro and Ghavamzadeh, Mohammad and Munos, R{\'e}mi},
  journal={Journal of Machine Learning Research},
  volume={13},
  pages={3041--3074},
  year={2012}
}

@BOOK{Gyorfi02DF,
  title = {A {D}istribution-{F}ree {T}heory of {N}onparametric {R}egression},
  publisher = {Springer-Verlag},
  year = {2002},
  author = {L. {G}y\"{o}rfi and M. {K}olher, M. {K}rzy\.{z}ak, H. {W}alk}
}

@ARTICLE{Vapnik71UC,
  author = {V. Vapnik and A. Chervonenkis},
  title = {On the uniform convergence of relative frequencies of events to their
	probabilities},
  journal = {Theory of Probability and its Applications},
  year = {1971},
  volume = {16},
  pages = {264--280}
}


@article {Canbolat12AI,
   author = {Canbolat, P. and Rothblum, U.},
   affiliation = {Faculty of Industrial Engineering and Management, The Technion—Israel Institute of Technology, Haifa, 32000 Israel},
   title = {({A}pproximate) iterated successive approximations algorithm for sequential decision processes},
   journal = {Annals of Operations Research},
   publisher = {Springer Netherlands},
   keyword = {Business and Economics},
   pages = {1-12} ,
year={2012}
}

@techreport{Scherrer12AM-Tech,
     title = {{Approximate Modified Policy Iteration}},
    author = {B. Scherrer and V. Gabillon and M. Ghavamzadeh and M. Geist},
    type = {Technical Report},
    institution = {inria-00697169},
    year = {2012}
 }

@inproceedings{Scherrer12AM,
     title = {{Approximate Modified Policy Iteration}},
    author = {B. Scherrer and M. Ghavamzadeh and V. Gabillon and M. Geist},
    BOOKTITLE = "Proceedings of the Twenty Ninth International Conference on Machine Learning",
    PAGES = "1207-1214",
    year = {2012}
 }
 
 @article{scherrerapproximate,
  title={Approximate Dynamic Programming for Two-Player Zero-Sum Markov Games},
  author={Scherrer, Bruno},
   booktitle = {Proceedings of the Thirty Second International Conference on Machine
               Learning},
  year      = {2015},
}

 
@article{Scherrer14AM,
     title = {{Approximate Modified Policy Iteration}},
    author = {B. Scherrer and M. Ghavamzadeh and V. Gabillon and Boris Lesner and M. Geist},
    journal = "Submitted to Journal of Machine Learning Research",
    year = {2014}
 }

@misc{Fahey03TA,
  author    = {C. Fahey},
  title     = {Tetris {A}{I}, {C}omputer plays {T}etris},
  year      = {2003},
  note      = {\url{http://colinfahey.com/tetris/tetris.html}}
}

@article{Thiery09IL,
    hal_id = {inria-00418930},
  url = {http://hal.inria.fr/inria-00418930},
    title = {{Improvements on Learning Tetris with Cross Entropy}},
    author = {C. Thi\'ery and B. Scherrer},
   
    affiliation = {MAIA - INRIA Lorraine - LORIA},
    publisher = {ICGA},
    journal = {International Computer Games Association Journal},
    volume = {32},
    audience = {international },
    year = {2009},
    pdf = {http://hal.inria.fr/inria-00418930/PDF/article.pdf},
}

@article{Thiery09BC,
    hal_id = {inria-00418954},
    url = {http://hal.inria.fr/inria-00418954},
    title = {{Building Controllers for Tetris}},
    author = {C. Thi\'ery and B. Scherrer},
  
   
    affiliation = {MAIA - INRIA Lorraine - LORIA},
    publisher = {ICGA},
    pages = {3-11},
    journal = {International Computer Games Association Journal},
    volume = {32},
    audience = {international },
    year = {2009},
    pdf = {http://hal.inria.fr/inria-00418954/PDF/article.pdf},
}


@article{Burgiel97HL,
  author    = {H. Burgiel},
  title     = {How to {L}ose at {T}etris},
  journal   = {Mathematical Gazette},
  year      = {1997},
  volume    = {81},
  pages     = {194-200}
}



@inproceedings{Cai11PT,
    author = {Zhongjie Cai and Dapeng Zhang and Bernhard Nebel},
    title = {Playing Tetris Using Bandit-Based {M}onte-{C}arlo Planning},
    year = {2011},
    Booktitle = {AISB Symposium: AI and Games}
}

@article{Szita06LT,
  author    = {I. Szita and A. L{\H{o}}rincz},

  title     = {Learning {T}etris {U}sing the {N}oisy {C}ross-{E}ntropy {M}ethod},
  journal   = {Neural Computation},
  volume    = {18},
  number    = {12},
  year      = {2006},
  pages     = {2936-2941},
}

@Article{Vanroy96FB,
  author = 	 {J. Tsitsiklis and Van Roy, B.},
  title = 	 {{Feature-Based Methods for Large Scale Dynamic Programming}},
  journal = 	 {Machine Learning},
  year = 	 1996,
  volume =	 22,
  pages =	 {59-94}
}
@book{Bertsekas96ND,
    author = {Bertsekas, D.  and Tsitsiklis, J.},
    howpublished = {Hardcover},
    publisher = {{Athena Scientific}},
    title = {{Neuro-Dynamic Programming}},
    year = {1996}
}


@ARTICLE{Dimitrakakis08RS,
  author = {C. Dimitrakakis and M. Lagoudakis},
  title = {{Rollout Sampling Approximate Policy Iteration}},
  journal = {Machine Learning Journal},
  year = {2008},
  volume = {72},
  pages = {157--171},
  number = {3}
}

@techreport{Thiery10PB,
    title = {{Performance Bound for Approximate Optimistic Policy Iteration}},
    author = {C. Thi\'ery and B. Scherrer},
    type = {Technical Report},
    institution = {INRIA},
    year = {2010}}
    
  @ARTICLE{Hansen01CD,
    author = {N. Hansen and A. Ostermeier},
    title = {{Completely Derandomized Self-Adaptation in Evolution Strategies}},
    journal = {Evolutionary Computation},
    year = {2001},
    volume = {9},
    pages = {159--195}
}



@article{Chang11LI,
 author = {C. Chang and C. Lin},
 title = {{LIBSVM}: A library for support vector machines},
 journal = {ACM Transactions on Intelligent Systems and Technology},
 issue_date = {April 2011},
 volume = {2},
 number = {3},
 month = may,
 year = {2011},
 pages = {27:1--27:27},
 articleno = {27},
 numpages = {27},
 publisher = {ACM},
 address = {New York, NY, USA}
} 

@misc{Thiery10MD,
  author    = {C. Thi\'ery and B. Scherrer},
  title = {{MDPT}etris features documentation},
  year      = {2010},
  note      = {\url{http://mdptetris.gforge.inria.fr/doc/feature_functions_8h.html}}
}

@inproceedings{Demaine03TH,
  author       = {E. Demaine and S. Hohenberger and D. Liben-Nowell},
  title        = {{Tetris is Hard, Even to Approximate}},
  booktitle    = {Proceedings of the Ninth International Computing and Combinatorics Conference},
  year         = {2003},
  pages        = {351-363}
}

@article{Scherrer13PB,
    title = {{Performance Bounds for $\lambda$-Policy Iteration and Application to the Game of Tetris}},
    author = {B. Scherrer},
    pages = {1175-1221},
    journal = {Journal of Machine Learning Research},
    volume = {14},
    year = {2013}
}

@inproceedings{Furmston12UP,
  author    = {T. Furmston and D. Barber},
  title     = {{A Unifying Perspective of Parametric Policy Search Methods for Markov Decision Processes}},
  booktitle = {Proceedings of the Advances in Neural Information Processing Systems 26},
  year      = {2012},
  pages     = {2726-2734}
}


@inproceedings{Kakade01NP,
  author    = {S. Kakade},
  title     = {A Natural Policy Gradient},
  booktitle = {Proceedings of the Advances in Neural Information Processing Systems 15},
  year      = {2001},
  pages     = {1531-1538}
}

@book{Farias06TS,
  author    = {V. Farias and  Van Roy, B.},
  title     = {Tetris: A Study of Randomized Constraint Sampling},
  booktitle = {Probabilistic and Randomized Methods for Design Under Uncertainty},
  publisher = {Springer-Verlag},
  year      = {2006}
}

@inproceedings{Ramon04NS,
  author    = {J. Ramon and K. Driessens},
  title     = {On the numeric stability of {G}aussian processes regression for relational reinforcement learning},
  booktitle = {ICML Workshop on Relational Reinforcement Learning},
  pages     = {10-14},
  year      = {2004},
}

@misc{Llima05XR,
  author    = {R. Llima},
  title     = {Xtris readme},
  year      = {2005},
  note       = {http://www.iagora.com/$\sim$espel/xtris/README},
}



@ARTICLE{Barto83NE,
  author = {A. Barto and R. Sutton and C. Anderson},
  title = {{Neuron-Like Elements that can Solve Difficult Learning Control Problems}},
  journal = {IEEE Transaction on Systems, Man and Cybernetics},
  year = {1983},
  volume = {13},
  pages = {835-846}
}



@INPROCEEDINGS{Maillard10FS,
  author = {O. Maillard and R. Munos and A. Lazaric and M. Ghavamzadeh},
  title = {{Finite-Sample Analysis of {B}ellman Residual Minimization}},
  booktitle = {Proceedings of the Second Asian Conference on Machine Learning},
  year = {2010}
}

@inproceedings{Rexakis12DP,
  author    = {I. Rexakis and
               M. Lagoudakis},
  title     = {{Directed Policy Search Using Relevance Vector Machines}},
  booktitle = {IEEE Twenty-Fourth International Conference on Tools with Artificial Intelligence},
  year      = {2012},
  pages     = {25-32}
}

@inproceedings{Pires13CS,
	Author = {Pires, B.A. and Ghavamzadeh, M. and Szepesv{\'a}ri, {\relax Cs}aba},
	Booktitle = {Proceedings of the Thirtieth International Conference on Machine Learning},
	Title = {{Cost-sensitive Multiclass Classification Risk Bounds}},
	Year = {2013}
	}
	
	@article{Shirazi12CS,
  author    = {H. Masnadi-Shirazi and
               N. Vasconcelos and
               A. Iranmehr},
  title     = {{Cost-Sensitive Support Vector Machines}},
  journal   = {CoRR},
  volume    = {abs/1212.0975},
  year      = {2012},
  ee        = {http://arxiv.org/abs/1212.0975},
  bibsource = {DBLP, http://dblp.uni-trier.de}
}

@article{Benbouzid12MB,
 author = {Benbouzid, D. and Busa-Fekete, R. and Casagrande, N. and Collin, F.-D. and K{\'e}gl, B.},
 title = {{MULTIBOOST: A Multi-purpose Boosting Package}},
 journal = {Journal Machine Learning Research},
 volume = {13},
 month = mar,
 year = {2012},
 pages = {549--553}
}

@inproceedings{Gabillon11MB,
  author    = {V. Gabillon and
               M. Ghavamzadeh and
               A. Lazaric and
               S. Bubeck},
  title     = {{Multi-Bandit Best Arm Identification}},
  booktitle = {Proceedings of the Advances in Neural Information Processing Systems 25},
  year      = {2011},
  pages     = {2222-2230}
}

@inproceedings{Gabillon12BA,
  author    = {V. Gabillon and
               M. Ghavamzadeh and
               A. Lazaric},
  title     = {{Best Arm Identification: A Unified Approach to Fixed Budget
               and Fixed Confidence}},
  booktitle = {Proceedings of the Advances in Neural Information Processing Systems 26},
  year      = {2012},
  pages     = {3221-3229}
}


@article{Auer02FA,
	Author = {P. Auer and N. Cesa-Bianchi and P. Fischer},
	Journal = {Machine Learning},
	Pages = {235-256},
	Title = {Finite-Time Analysis of the Multi-Armed Bandit Problem},
	Volume = {47},
	Year = {2002}}
	
	
@inproceedings{Audibert10BA,
	Author = {J.-Y. Audibert and S. Bubeck and R. Munos},
	Booktitle = {Proceedings of the Twenty-Third Conference on Learning Theory},
	Pages = {41-53},
	Title = {{Best Arm Identification in Multi-Armed Bandits}},
	Year = {2010}}
	
	
@inproceedings{Kalyanakrishnan12PA,
	Author = {S. Kalyanakrishnan and A. Tewari and P. Auer and P. Stone},
	Booktitle = {Proceedings of the Twentieth International Conference on Machine Learning},
	Title = {{PAC Subset Selection in Stochastic Multi-armed Bandits}},
	Year = {2012}}
	
	
@inproceedings{Maurer09EM,
	Author = {A. Maurer and M. Pontil},
	Booktitle = {Proceedings of the Twenty-Second Conference on Learning Theory},
	Date-Added = {2011-05-30 14:33:51 +0200},
	Date-Modified = {2011-05-30 14:33:51 +0200},
	Title = {{Empirical Bernstein Bounds and Sample-Variance Penalization}},
	Year = {2009}}
	
	
@inproceedings{Mnih08EB,
	Author = {V. Mnih and {\relax Cs}aba Szepesv\'{a}ri and J.-Y. Audibert},
	Booktitle = {Proceedings of the Twenty-Fifth International Conference on Machine Learning},
	Pages = {672-679},
	Title = {Empirical {B}ernstein stopping},
	Year = {2008}}



@PhdThesis{Kalyanakrishnan11LM,
  author =       "S. Kalyanakrishnan",
  title =        "Learning Methods for Sequential Decision Making with Imperfect Representations",
  school =       "Department of Computer Science, The University of Texas at Austin",
  year =         "2011",
  address =   "Austin, Texas, USA",
  month =     "December",
  note = "Published as UT Austin Computer Science Technical Report TR-11-41",
}


@article{Even-Dar06AE,
	Author = {E. Even-Dar and S. Mannor and Y. Mansour},
	Journal = {Journal of Machine Learning Research},
	Pages = {1079-1105},
	Title = {Action Elimination and Stopping Conditions for the Multi-Armed Bandit and Reinforcement Learning Problems},
	Volume = {7},
	Year = {2006}}
	
	
	@article{Antos10AL,
  author    = {Antos, Andr{\'a}s and Grover, Varun and  {\relax Cs}aba Szepesv{\'a}ri},
  title     = {{Active Learning in Heteroscedastic Noise}},
  journal={Theoretical Computer Science},
  volume    = {411},
  number    = {29-30},
  year      = {2010},
  pages     = {2712-2728}
}

@inproceedings{Karnin13AO,
  title={{Almost Optimal Exploration in Multi-Armed Bandits}},
  author={Karnin, Z. and Koren, T. and Somekh, O.},
  booktitle={Proceedings of the Thirtieth International Conference on Machine Learning},
  year={2013}
}


   
   
   
@inproceedings{Bubeck09PE,
	Author = {S. Bubeck and R. Munos and G. Stoltz},
	Booktitle = {Proceedings of the Twentieth International Conference on Algorithmic Learning Theory},
	Pages = {23-37},
	Title = {{Pure Exploration in Multi-Armed Bandit Problems}},
	Year = {2009}}
	
	
	
@article{Robbins52SA,
	Author = {H. Robbins},
	Journal = {Bulletin of the American Mathematics Society},
	Pages = {527-535},
	Title = {{Some Aspects of the Sequential Design of Experiments}},
	Volume = {58},
	Year = {1952}}



@inproceedings{Deng11AL,
	Author = {K. Deng and J. Pineau and S. Murphy},
	Booktitle = {IEEE Symposium on Adaptive Dynamic Programming and Reinforcement Learning},
	Title = {{Active Learning for Personalizing Treatment}},
	Year = {2011}}
	

@inproceedings{Maron93HR,
	Author = {O. Maron and A. Moore},
	Booktitle = {Proceedings of the Advances in Neural Information Processing Systems 7},
	Title = {{Hoeffding races: Accelerating model selection search for classification and function approximation}},
	Year = {1993}}
	
	
	

@inproceedings{Bubeck12MM, 
    Author = {T. Wang and N. Viswanathan and S. Bubeck}, 
    Title = {{Multiple Identifications in Multi-Armed Bandits}}, 
    Volume = {28}, 
    Year = {2013}, 
    Booktitle = {Proceedings of the Thirtiethth International Conference on Machine Learning}, 
    Pages = {258-265} 
   }

@article{Keller00CN,
author = {Keller, M. and McCullough, J. and Klein, D. and Arnow, B. and Dunner, D. and Gelenberg, A. and Markowitz, J. and Nemeroff, C. and Russell, J. and Thase, M. },
title = {A Comparison of Nefazodone, the Cognitive Behavioral-Analysis System of Psychotherapy, and Their Combination for the Treatment of Chronic Depression},
journal = {New England Journal of Medicine},
volume = {342},
number = {20},
pages = {1462-1470},
year = {2000},

}

@inproceedings{Gabillon13AD,
  author    = {V. Gabillon and
               M. Ghavamzadeh and
               B. Scherrer},
  title     = {{Approximate Dynamic Programming Finally Performs Well in the Game of Tetris}},
  booktitle = {Proceedings of the Advances in Neural Information Processing Systems 27},
  year      = {2013},
}



@ARTICLE{Garivier13KL,
TITLE = {Kullback-Leibler Upper Confidence Bounds for Optimal Sequential Allocation},
AUTHOR = {O. Cappé and A. Garivier and O. Maillard and R. Munos and G. Stoltz},
JOURNAL = {Annals of Statistics},
YEAR = {2013},
VOLUME = {41},
NUMBER = {3},
PAGES = {1516--1541},
ARXIV = {1210.1136 },
HAL = {00738209},
}


@article{Honda11AO,
  author = {Honda, J. and Takemura, A.},
 journal = {Machine Learning},
  keywords = {dblp},
  number = 3,
  pages = {361-391},
  title = {An asymptotically optimal policy for finite support models in the multiarmed bandit problem.},
  volume = 85,
  year = 2011
}

@InProceedings{Kaufmann13IC,
  author =       "Kaufmann, {\'E}milie and Kalyanakrishnan, S.",
  title =        "Information Complexity in Bandit Subset Selection",
  booktitle =    "Proceedings of the Twenty-Sixth Conference on Learning Theory",
  pages =     "228--251",
  year =         "2013",
}

@inproceedings{Kaufmann12TS,
  author    = {{\'E}milie Kaufmann and
               N. Korda and
               R. Munos},
  title     = {Thompson Sampling: An Asymptotically Optimal Finite-Time
               Analysis},
  booktitle = {Proceedings of the Twenty-Fourth International Conference on Algorithmic Learning Theory},
  year      = {2012},
  pages     = {199-213}
}


@InProceedings{Gabillon10RA,
 title={{Rollout Allocation Strategies for Classification-based Policy Iteration}},
  author={Gabillon, V. and Lazaric, A. and Ghavamzadeh, M.},
  year={2010},
  booktitle = {Workshop on Reinforcement Learning and Search in Very Large Spaces}
}

@article{Schweitzer85GP,
  author = {Schweitzer, P. and Seidman, A.},
  journal = {Journal of Mathematical Analysis and Applications},
  pages = {568-582},
  title = {Generalized Polynomial Approximations in Markovian Decision Processes},
  volume = 110,
  year = 1985
}



@InProceedings{Agarwal13SS,
   booktitle = {Proceedings of the Thirtieth International Conference on Machine Learning},
   year = {2013},
   title = {{Selective sampling algorithms for cost-sensitive	 multiclass prediction}},
   author = {A. Agarwal}
   
    } 
    
@inproceedings{Farahmand12GC,
     author = {Farahmand, A.-M. and Precup, D. and Ghavamzadeh, M.},
    booktitle = {Proceedings of the European Workshop on Reinforcement Learning (EWRL)},
   
    location = {Edinburgh, Scotland},
    month = jun,
    pages = {1--11},
    posted-at = {2013-01-15 17:18:56},
    priority = {2},
    title = {{Generalized Classification-based Approximate Policy Iteration}},
    year = {2012}
}    
@INPROCEEDINGS{Kakade02AO,
    author = {S. Kakade and J. Langford},
    title = {Approximately Optimal Approximate Reinforcement Learning},
    booktitle = {Proceedings of the 19th International Conference on Machine Learning},
    year = {2002},
    pages = {267--274}
    
    }
@article{Grondman12AS,
  author    = {I. Grondman and
               L. Busoniu and
               G. Lopes and
               R. Babuska},
  title     = {{A Survey of Actor-Critic Reinforcement Learning: Standard
               and Natural Policy Gradients}},
  journal   = {IEEE Transactions on Systems, Man, and Cybernetics, Part
               C},
  volume    = {42},
  number    = {6},
  year      = {2012},
  pages     = {1291-1307}
}    
    
@inproceedings{Ghavamzadeh12CG,
  author    = {M. Ghavamzadeh and
               A. Lazaric},
  title     = {{Conservative and Greedy Approaches to Classification-Based
               Policy Iteration}},
  booktitle = {Proceedings of the Twenty-Sixth AAAI Conference on Artificial
               Intelligence},
  year      = {2012}
 
}

@inproceedings{Scherrer12OT,
  author    = {B. Scherrer and
               B. Lesner},
  title     = {{On the Use of Non-Stationary Policies for Stationary Infinite-Horizon
               Markov Decision Processes}},
  booktitle = {NIPS},
  year      = {2012},
  pages     = {1835-1843}
 }    
 
 
@BOOK{Howard60DP,
  title = {Dynamic Programming and {M}arkov Processes},
  publisher = {The MIT Press},
  year = {1960},
  author = {R. Howard},
  address = {Cambridge, MA}
}

@Article{Pietquin11SE,
author = {O. Pietquin and M. Geist and S. Chandramohan and H. Frezza-Buet},
title = {{Sample-Efficient Batch Reinforcement Learning for Dialogue Management Optimization}},
journal = {ACM Transactions on Speech and Language Processing},
year = {2011},
volume = {7},
number = {3},
pages = {7:1-7:21},
month = {May}

}
@article{Tesauro94TD,
  author    = {G. Tesauro},
  title     = {TD-Gammon, a Self-Teaching Backgammon Program, Achieves
               Master-Level Play},
  journal   = {Neural Computation},
  volume    = {6},
  number    = {2},
  year      = {1994},
  pages     = {215-219}
}

 @INPROCEEDINGS{Ng04IA,
    author = {A. Ng and H. Jin Kim and M. Jordan and S. Sastry},
    title = {{Inverted autonomous helicopter flight via reinforcement learning}},
    booktitle = {International Symposium on Experimental Robotics},
    year = {2004},
    publisher = {MIT Press}
}   

@InProceedings{Goschin13CE,
   booktitle = {Proceedings of the Thirtieth International Conference on Machine Learning},
   year = {2013},
   title = {{The Cross-Entropy Method Optimizes for Quantiles}},
   author = {Goschin, S. and Weinstein, A. and Littman, M.},
   pages = {1193-1201}
   } 
   
%   P. Glynn, Likelihood ratio gradient estimation: an overview, in Proceedings of the 1987 Winter Simulation Conference, Atlanta, GA, 1987, pp. 366--375. 
@InProceedings{Glynn87LR,
   booktitle = {Proceedings of the 1987 Winter Simulation Conference, Atlanta, GA},
   year = {1987},
   title = {{Likelihood ratio gradient estimation: an overview}},
   author = {P. Glynn},
   pages = {366--375}
   }    
   
   @article{Williams92SS,
  author = {Williams, R.J.},
  journal = {Machine Learning},
  number = 3,
  pages = {229--256},
  publisher = {Springer},
  title = {{Simple statistical gradient-following algorithms for connectionist reinforcement learning}},
  volume = 8,
  year = 1992
}
   
@article{Auer03NS,
 author = {Auer, Peter and Cesa-Bianchi, Nicol\'o and Freund, Yoav and Schapire, Robert},
 title = {{The Nonstochastic Multiarmed Bandit Problem}},
 journal = {SIAM Journal on Computing},
 issue_date = {2003},
 volume = {32},
 number = {1},
 month = jan,
 year = {2003},
 pages = {48--77},
 numpages = {30}
} 

@inproceedings{Wang08AI,
  author    = {Y. Wang and
               J.-Y. Audibert and
               R. Munos},
  title     = {{Algorithms for Infinitely Many-Armed Bandits}},
  booktitle = {NIPS},
  year      = {2008},
  pages     = {1729-1736}
}




@inproceedings{Dani07TP,
  author    = {Varsha Dani and
               Thomas  Hayes and
               Sham Kakade},
  title     = {{The Price of Bandit Information for Online Optimization}},
  booktitle = {Proceedings of the Advances in Neural Information
               Processing Systems 21},
  year      = {2007}
}

@inproceedings{Carpentier11UC,
  author    = {A. Carpentier and
               A. Lazaric and
               M. Ghavamzadeh and
               R. Munos and
               P. Auer},
  title     = {{Upper-Confidence-Bound Algorithms for Active Learning in
               Multi-armed Bandits}},
  booktitle = {Proceedings of the Twenty-Second International Conference on Algorithmic Learning Theory},
  year      = {2011},
  pages     = {189-203}
}

@inproceedings{Kalyanakrishnan10ES,
	Author = {S. Kalyanakrishnan and P. Stone},
	Booktitle = {Proceedings of the Twenty-Seventh International Conference on Machine Learning},
	Pages = {511-518},
	Title = {{Efficient Selection of Multiple Bandit Arms: Theory and Practice}},
	Year = {2010}}
	
	@ARTICLE{Mannor04TS,
    author = {S. Mannor and J. Tsitsiklis},
 title = {{The Sample Complexity of Exploration in the Multi-Armed Bandit Problem}},
 journal = {Journal of  Machine Learning Research},
 volume = {5},
 year = {2004}, 
 pages = {623--648}
}

@ARTICLE{Baxter01IP,
    AUTHOR = "J. Baxter and P. Bartlett",
    TITLE = "Infinite-Horizon Policy-Gradient Estimation",
    JOURNAL = "Journal of Artificial Intelligence Research",
    VOLUME = "15",
    PAGES = "319-350",
    YEAR = "2001"}


@PHDTHESIS{Marbach98SM,
    AUTHOR = "P. Marbach",
    TITLE = "Simulated-Based Methods for {M}arkov Decision Processes",
    SCHOOL = "Massachusetts Institute of Technology",
    YEAR = "1998"}


@Book{Bellman57DP,
  author =       "Bellman, R.",
  title =        "Dynamic Programming",
  publisher =    "Princeton University Press",
  year =         "1957",
  address =   "Princeton, NJ, USA"
}
	
@article{Nunen76AS,
year={1976},
journal={Zeitschrift für Operations Research},
volume={20},
number={5},
title={A set of successive approximation methods for discounted Markovian decision problems},
publisher={Physica-Verlag},
author={Nunen, J.},
pages={203-208}
}
@INPROCEEDINGS{Mannor03CE,
    author = {Shie Mannor and Reuven Rubinstein and Yohai Gat},
    title = {{The Cross Entropy method for Fast Policy Search}},
    booktitle = {In Proceedings of the Twentieth International Conference on Machine Learning},
    year = {2003},
    pages = {512--519},
    publisher = {Morgan Kaufmann}
}

@PHDTHESIS{Sutton84TC, 
    AUTHOR = "R. Sutton",
    TITLE = "Temporal credit assignment in reinforcement learning",
    SCHOOL = "University of Massachusetts Amherst",
    YEAR = "1984"}

@article{Simester06DC,
 author = {Simester, Duncan I. and Sun, Peng and Tsitsiklis, John },
 title = {{Dynamic Catalog Mailing Policies}},
 journal = {Management Science},
 volume = {52},
 number = {5},
 month = may,
 year = {2006},
 pages = {683--696},
 publisher = {INFORMS}
} 

@TECHREPORT{Marbach97ND,
    author = {Peter Marbach and John Tsitsiklis},
    title = {{A Neuro-Dynamic Programming Approach to Call Admission Control in Integrated Service Networks: The Single Link Case}},
    institution = {Decision Syst. Rep. LIDS-P-2402, Massachusetts Institute of Technology},
    year = {1997}
}


@inproceedings{Audibert07TB,
  author    = {Jean-Yves Audibert and
               R{\'e}mi Munos and
               {\relax Cs}aba Szepesv{\'a}ri},
  title     = {{Tuning Bandit Algorithms in Stochastic Environments}},
  booktitle = {Proceedings of the Eighteenth International Conference on Algorithmic Learning Theory},
  year      = {2007},
  pages     = {150-165}
}

@inproceedings{Chapelle11EE,
  title={{An empirical evaluation of thompson sampling}},
  author={Chapelle, Olivier and Li, Lihong},
  booktitle={Proceedings of the Advances in Neural Information
               Processing Systems 25},
  pages={2249--2257},
  year={2011}
}

@inproceedings{Kiekintveld:2013,
 author = {Kiekintveld, Christopher and Islam, Towhidul and Kreinovich, Vladik},
 title = {Security Games with Interval Uncertainty},
 booktitle = {Proceedings of the 2013 International Conference on Autonomous Agents and Multi-agent Systems},
 series = {AAMAS '13},
 year = {2013},
 isbn = {978-1-4503-1993-5},
 location = {St. Paul, MN, USA},
 pages = {231--238},
 numpages = {8},
 acmid = {2484959},
 publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
 address = {Richland, SC},
 keywords = {algorithms, game theory, interval uncertainty, security games}
} 

@article{granick2005faking,
  title={Faking It: Calculating Loss in Computer Crime Sentencing},
  author={Granick, Jennifer S},
  journal={ISJLP},
  volume={2},
  pages={207},
  year={2005},
  publisher={HeinOnline}
}

@article{swire2009no,
  title={No cop on the beat: Underenforcement in e-commerce and cybercrime},
  author={Swire, Peter},
  journal={J. on Telecomm. \& High Tech. L.},
  volume={7},
  pages={107},
  year={2009},
  publisher={HeinOnline}
}

@article{bubeck2012regret,
  title={Regret analysis of stochastic and nonstochastic multi-armed bandit problems},
  author={Bubeck, S{\'e}bastien and Cesa-Bianchi, Nicolo},
  journal={arXiv preprint arXiv:1204.5721},
  year={2012}
}

\@inproceedings{chen2014combinatorial,
  title={Combinatorial pure exploration of multi-armed bandits},
  author={Chen, Shouyuan and Lin, Tian and King, Irwin and Lyu, Michael R and Chen, Wei},
  booktitle={Advances in Neural Information Processing Systems},
  pages={379--387},
  year={2014}
}

@inproceedings{krause2011randomized,
  title={Randomized sensing in adversarial environments},
  author={Krause, Andreas and Roper, Alex and Golovin, Daniel},
  booktitle={IJCAI Proceedings-International Joint Conference on Artificial Intelligence},
  volume={22},
  number={3},
  pages={2133},
  year={2011}
}

@article{goldberg2014query,
  title={Query Complexity of Approximate Equilibria in Anonymous Games},
  author={Goldberg, Paul W and Turchetta, Stefano},
  journal={arXiv preprint arXiv:1412.6455},
  year={2014}
}

@inproceedings{blum2014learning, title={Learning optimal commitment to overcome insecurity}, author={Blum, Avrim and Haghtalab, Nika and Procaccia, Ariel D}, booktitle={Advances in Neural Information Processing Systems}, pages={1826--1834}, year={2014} }
@incollection{letchford2009learning, title={Learning and approximating the optimal strategy to commit to}, author={Letchford, Joshua and Conitzer, Vincent and Munagala, Kamesh}, booktitle={Algorithmic Game Theory}, pages={250--262}, year={2009}, publisher={Springer} }


@article{munos2014bandits,
  title={From bandits to Monte-Carlo Tree Search: The optimistic principle applied to optimization and planning},
  author={Munos, R{\'e}mi},
  year={2014}
}


@article{cesa2012combinatorial,
  title={Combinatorial bandits},
  author={Cesa-Bianchi, Nicolo and Lugosi, G{\'a}bor},
  journal={Journal of Computer and System Sciences},
  volume={78},
  number={5},
  pages={1404--1422},
  year={2012},
  publisher={Elsevier}
}
@incollection{NIPS2012_4753,
title = {Risk-Aversion in Multi-armed Bandits},
author = {Sani, Amir and Lazaric, Alessandro and R\'{e}mi Munos},
booktitle = {Advances in Neural Information Processing Systems 25},
editor = {F. Pereira and C.J.C. Burges and L. Bottou and K.Q. Weinberger},
pages = {3275--3283},
year = {2012},
publisher = {Curran Associates, Inc.},
}


@inproceedings{auer2009near,
  title={Near-optimal regret bounds for reinforcement learning},
  author={Auer, Peter and Jaksch, Thomas and Ortner, Ronald},
  booktitle={Advances in neural information processing systems},
  pages={89--96},
  year={2009}
}



@inproceedings{jain2011double,
  title={A double oracle algorithm for zero-sum security games on graphs},
  author={Jain, Manish and Korzhyk, Dmytro and Van{\v{e}}k, Ond{\v{r}}ej and Conitzer, Vincent and P{\v{e}}chou{\v{c}}ek, Michal and Tambe, Milind},
  booktitle={The 10th International Conference on Autonomous Agents and Multiagent Systems-Volume 1},
  pages={327--334},
  year={2011},
  organization={International Foundation for Autonomous Agents and Multiagent Systems}
}

@inproceedings{gabillon2013adaptive,
  title={Adaptive submodular maximization in bandit setting},
  author={Gabillon, Victor and Kveton, Branislav and Wen, Zheng and Eriksson, Brian and Muthukrishnan, S},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2697--2705},
  year={2013}
}

@article{russo2014information,
  title={An information-theoretic analysis of thompson sampling},
  author={Russo, Daniel and Van Roy, Benjamin},
  journal={arXiv preprint arXiv:1403.5341},
  year={2014}
}

@article{LeslieCollins06,
author = {Leslie, David S. and Collins, E.J.},
doi = {10.1016/j.geb.2005.08.005},
file = {:Users/leslied/Library/Application Support/Mendeley Desktop/Downloaded/Leslie, Collins - 2006 - Generalised weakened fictitious play.pdf:pdf},
issn = {08998256},
journal = {Games and Economic Behavior},
keywords = {actor,best response differential inclusion,critic process,fictitious play,stochastic approximation},
number = {2},
pages = {285--298},
title = {{Generalised weakened fictitious play}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S089982560500103X},
volume = {56},
year = {2006}
}

@article{ChapmanEtAl2013,
abstract = {In this paper, we address the problem of convergence to Nash equilibria in games with rewards that are initially unknown and must be estimated over time from noisy observations. These games arise in many real-world applications, whenever rewards for actions cannot be prespecified and must be learned online, but standard results in game theory do not consider such settings. For this problem, we derive a multiagent version of \$\backslash mathcal\{Q\}\$-learning to estimate the reward functions using novel forms of the \$\backslash epsilon\$-greedy learning policy. Using these \$\backslash mathcal\{Q\}\$-learning schemes to estimate reward functions, we then provide conditions guaranteeing the convergence of adaptive play and the better-reply processes to Nash equilibria in potential games and games with more general forms of acyclicity, and of regret matching to the set of correlated equilibria in generic games. A secondary result is that we prove the strong ergoditicity of stochastic adaptive play and stochastic better-reply processes in the ca...},
author = {Chapman, Archie C. and Leslie, David S. and Rogers, Alex and Jennings, Nicholas R.},
doi = {10.1137/120893501},
issn = {0363-0129},
journal = {SIAM Journal on Control and Optimization},
keywords = {68T05,68W15,91A10,distributed optimization,potential games,reinforcement learning,strong ergodicity},
language = {en},
month = jan,
number = {4},
pages = {3154--3180},
publisher = {Society for Industrial and Applied Mathematics},
title = {{Convergent Learning Algorithms for Unknown Reward Games}},
url = {http://epubs.siam.org/doi/abs/10.1137/120893501},
volume = {51},
year = {2013}
}

@article{MayEtAl2012,
author = {May, BC and Korda, N and Lee, A and Leslie, DS},
file = {:Users/leslied/Library/Application Support/Mendeley Desktop/Downloaded/May et al. - 2012 - Optimistic Bayesian sampling in contextual-bandit problems.pdf:pdf},
journal = {The Journal of Machine Learning Research},
pages = {2069--2106},
title = {{Optimistic Bayesian sampling in contextual-bandit problems}},
url = {http://dl.acm.org/citation.cfm?id=2343711},
volume = {13},
year = {2012}
}

@article{LeslieCollins03,
author = {Leslie, David S and Collins, E J},
journal = {Annals of Applied Probability},
number = {4},
pages = {1231--1251},
title = {{Convergent Multiple-timescales Reinforcement Learning Algorithms in Normal Form Games}},
volume = {13},
year = {2003}
}
@article{LeslieCollins05,
author = {Leslie, David S and Collins, E J},
journal = {SIAM Journal on Control and Optimization},
pages = {495--514},
title = {{Individual Q-learning in normal form games}},
volume = {44},
year = {2005}
}
@article{PerkinsLeslie2012,
abstract = {The asymptotic pseudo-trajectory approach to stochastic approximation of Bena\"{\i}m, Hofbauer and Sorin is extended for asynchronous stochastic approximations with a set-valued mean field. The asynchronicity of the process is incorporated into the mean field to produce convergence results which remain similar to those of an equivalent synchronous process. In addition, this allows many of the restrictive assumptions previously associated with asynchronous stochastic approximation to be removed. The framework is extended for a coupled asynchronous stochastic approximation process with set-valued mean fields. Two-timescales arguments are used here in a similar manner to the original work in this area by Borkar. The applicability of this approach is demonstrated through learning in a Markov decision process.},
author = {Perkins, Steven and Leslie, David},
doi = {10.1214/11-SSY056.},
journal = {Stochastic Systems},
keywords = {Asynchronous stochastic approximation,differential inclusion,two-timescales.},
language = {en},
pages = {409--446},
publisher = {INFORMS Applied Probability Society},
title = {{Asynchronous stochastic approximation with differential inclusions}},
url = {http://www.i-journals.org/ssy/viewarticle.php?id=56},
volume = {2},
year = {2012}
}
@article{PerkinsLeslie2014,
author = {Perkins, Steven and Leslie, David S.},
doi = {10.1016/j.jet.2014.04.008},
file = {:Users/leslied/Downloads/1-s2.0-S0022053114000623-main.pdf:pdf},
journal = {Journal of Economic Theory},
pages = {179--213},
title = {{Stochastic Fictitious Play with Continuous Action Sets}},
url = {http://www.sciencedirect.com/science/journal/00220531},
volume = {152},
year = {2014}
}
@article{LarsenEtAl2010,
abstract = {Reinforcement learning models generally assume that a stimulus is presented that allows a learner to unambiguously identify the state of nature, and the reward received is drawn from a distribution that depends on that state. However, in any natural environment, the stimulus is noisy. When there is state uncertainty, it is no longer immediately obvious how to perform reinforcement learning, since the observed reward cannot be unambiguously allocated to a state of the environment. This letter addresses the problem of incorporating state uncertainty in reinforcement learning models. We show that simply ignoring the uncertainty and allocating the reward to the most likely state of the environment results in incorrect value estimates. Furthermore, using only the information that is available before observing the reward also results in incorrect estimates. We therefore introduce a new technique, posterior weighted reinforcement learning, in which the estimates of state probabilities are updated according to the observed rewards (e.g., if a learner observes a reward usually associated with a particular state, this state becomes more likely). We show analytically that this modified algorithm can converge to correct reward estimates and confirm this with numerical experiments.The algorithm is shown to be a variant of the expectation-maximization algorithm, allowing rigorous convergence analyses to be carried out. A possible neural implementation of the algorithm in the cortico-basal-ganglia-thalamic network is presented, and experimental predictions of our model are discussed.},
author = {Larsen, Tobias and Leslie, David S and Collins, Edmund J and Bogacz, Rafal},
file = {:Users/leslied/Library/Application Support/Mendeley Desktop/Downloaded/Larsen et al. - 2010 - Posterior Weighted Reinforcement Learning with State Uncertainty.pdf:pdf},
journal = {Neural Computation},
pages = {1149--1179},
title = {{Posterior Weighted Reinforcement Learning with State Uncertainty}},
volume = {22},
year = {2010}
}
%TODO Update Sebastien multiple with ICML2013 and gabillon2013 NIPS KAUFman2013 at colt! and A Agrawal ICML 2013. Verify A-M and O.-A. talk about monte carlo in Tetris. generative model assumtoion. mbox for cross page hyperref
%CBPI algoritms SSSS

%tradeoff
%nips reference ICML 2013!! and COLT 2013
%reread all the conclusio of chapters.